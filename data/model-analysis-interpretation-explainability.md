# Post model-creation analysis, ML interpretation/explainability

## Libraries & packages

- [Yellowbrick](https://www.scikit-yb.org/en/latest/#yellowbrick-machine-learning-visualization) - is a suite of visual diagnostic tools called “Visualizers” that extend the Scikit-Learn API to allow human steering of the model selection process
- [Shap](https://github.com/slundberg/shap) - A unified approach to explain the output of any machine learning model
- [LIME](https://github.com/marcotcr/lime)
- [4 Python Libraries For Getting Better Model Interpretability](https://www.analyticsindiamag.com/4-python-libraries-for-getting-better-model-interpretability/)
- [Integrated Gradients: Axiomatic Attribution for Deep Networks](https://github.com/ankurtaly/Integrated-Gradients) | [Paper](https://arxiv.org/abs/1703.01365)
- [Resources on GitHub on interpretability](https://github.com/topics/interpretability)
- [Awesome Machine Learning Interpretability](https://github.com/jphall663/awesome-machine-learning-interpretability) - A Curated, but Probably Biased and Incomplete, List of Awesome Machine Learning Interpretability Resources

## Articles, blog posts, papers, notebooks, books, presentations

- [DataRobot: Model Interpretability - What is Model Interpretability in Machine Learning?](https://www.datarobot.com/wiki/interpretability/)
- [Model Interpretability with SHAP](http://www.f1-predictor.com/model-interpretability-with-shap/)
- [Interpreting bag of words models with SHAP](https://sararobinson.dev/2019/04/23/interpret-bag-of-words-models-shap.html)
- [Explain any machine learning model prediction - using SHAP](https://towardsdatascience.com/how-to-explain-any-machine-learning-model-prediction-30654b0c1c8)
- [Explain ML Models notebooks](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/explain-model)
- [How to explain the prediction of a ML model](https://lilianweng.github.io/lil-log/2017/08/01/how-to-explain-the-prediction-of-a-machine-learning-model.html)
- [Explaining complex machine learning models with LIME](https://datascienceplus.com/explaining-complex-machine-learning-models-with-lime/)
- Hermeneutic Investigations: ML Interpreation - why?: [Video](https://www.youtube.com/watch?v=pmdYlahqA_g) | [Slides](https://github.com/daplantagenet/iml.github.io/blob/master/Hermeneutic%20Investigations.pdf) by [Dean Allsopp](http://github.com/daplantagenet)
- [Explaining Explanations: An Overview ofInterpretability of Machine Learning](https://arxiv.org/pdf/1806.00069.pdf)
- [Explaining Black-Box Machine Learning Models](https://shirinsplayground.netlify.com/2018/07/explaining_ml_models_code_caret_iml/)
- [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)
- [R Machine Learning Projects by Dr. Sunil Kumar Chinnamgari: Model interpretability](https://www.oreilly.com/library/view/r-machine-learning/9781789807943/dcd398be-3488-423c-942c-69d1eac253f5.xhtml)
- [Hands-on Machine Learning with R: Interpretable Machine Learning](https://bradleyboehmke.github.io/HOML/iml.html)
- Tree SHAP
  - [Consistent Individualized Feature Attribution for Tree Ensembles ](https://arxiv.org/abs/1802.03888)
  - [Consistent feature attribution for tree ensembles](https://arxiv.org/abs/1706.06060)
- [Exact SHAP: A Unified Approach to Interpreting Model Predictions](https://arxiv.org/abs/1705.07874)
- [Integrated Gradients: Axiomatic Attribution for Deep Networks](https://arxiv.org/abs/1703.01365) | [GitHub](https://github.com/ankurtaly/Integrated-Gradients)
- [Know Data Science](https://www.linkedin.com/feed/update/urn:li:activity:6516283940658089984)
- [Understand How to answer Why](https://www.linkedin.com/feed/update/urn:li:activity:6519055798948204544)
- [Learning with Explanations](https://www.youtube.com/watch?v=m1GUhPgstvk) by [Tim Rocktäschel](https://rockt.github.io/)
- Towards Explainable AI: [Slides](../presentations/data/03-meetup-uk-2019/Towards-Explainable-AI.pdf) | [Video](https://www.youtube.com/watch?v=0yFjSs-azM4) | [Book: A Concise Introduction to Machine Learning](https://www.amazon.co.uk/Concise-Introduction-Machine-Learning/dp/0815384106/ref=tmm_pap_swatch_0?_encoding=UTF8&qid=1566160069&sr=8-2) by [Anita Faul](https://www.linkedin.com/in/anita-faul-123750104/) | GitHub repos based on the above book: [main repos](https://github.com/ACFaul?tab=repositories) | [Lecture Slides](https://github.com/ACFaul/LectureSlides) | [Clustering Python](https://github.com/ACFaul/Clustering-Python) | [Neural Networks Matlab](https://github.com/ACFaul/Neural-Networks-Matlab) | [Regression Matlab](https://github.com/ACFaul/Regression-Matlab) | [Sampling Matlab](https://github.com/ACFaul/Sampling-Matlab) | [Non Linear Classification Matlab](https://github.com/ACFaul/Non-Linear-Classification-Matlab) | [Linear Classification Matlab](https://github.com/ACFaul/Linear-Classification-Matlab) | [Clustering Matlab](https://github.com/ACFaul/Clustering-Matlab)
- [Machine Learning Project End to End with Python Code (data science focussed)](https://www.youtube.com/watch?v=ekV9QO5KHUY&list=PLcQCwsZDEzFkP9WMe6xvLrd_ZNGqoXOQY&fbclid=IwAR1z7XBl762FLyo-gVvdBDU1iCVqz89K1yfmJS1cbC4rZyEfF-jO30ZsYeY)
- [Machine learning model explainability through Shapley values](https://faculty.ai/blog/machine-learning-model-explainability-through-shapley-values/) by [Christiane Ahlheim](https://www.linkedin.com/in/christiane-ahlheim-498263b2/) & [Markus Kunesch](https://www.linkedin.com/in/markus-kunesch/)
- [Research on AI Safety](https://faculty.ai/research/) by [faculty.ai](https://faculty.ai)

# Contributing

Contributions are very welcome, please share back with the wider community (and get credited for it)!

Please have a look at the [CONTRIBUTING](../CONTRIBUTING.md) guidelines, also have a read about our [licensing](../LICENSE.md) policy.

---

Back to [Data page (table of contents)](README.md)</br>
Back to [main page (table of contents)](../README.md)
